# Transformers
Pytorch Implementation of Transformers Explained with Comments


## Intorduction

### The Transformer are based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.
### These models are superior in quality while being more parallelizable and requiring significantly less time to train.
### In this document we will describe the transformer model completely and finally make our transformer model in PyTorch and test it on Cornell Movie Dialogs Corpus to show some interesting result.